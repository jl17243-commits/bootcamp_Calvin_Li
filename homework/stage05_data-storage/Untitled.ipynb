{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52dcf751-c118-4410-a28b-46b8cd90a1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_DIR: C:\\Users\\Bobli\\bootcamp_Calvin_Li\\homework\\homework05\\data\\raw\n",
      "PROC_DIR: C:\\Users\\Bobli\\bootcamp_Calvin_Li\\homework\\homework05\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib, datetime as dt\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "RAW_DIR = pathlib.Path(os.getenv(\"DATA_DIR_RAW\", \"data/raw\"))\n",
    "PROC_DIR = pathlib.Path(os.getenv(\"DATA_DIR_PROCESSED\", \"data/processed\"))\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"RAW_DIR:\", RAW_DIR.resolve())\n",
    "print(\"PROC_DIR:\", PROC_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2036f5-9999-4cce-8c40-15348f8c0628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    10 non-null     datetime64[ns]\n",
      " 1   ticker  10 non-null     object        \n",
      " 2   price   10 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 368.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dates = pd.date_range(\"2024-01-01\", periods=10, freq=\"D\")\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'ticker': ['AAPL']*10,\n",
    "    'price': 150 + np.random.randn(10).cumsum()\n",
    "})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e39299ba-a0b0-46d2-b696-d3768f5d7c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Parquet → data\\processed\\prices_20250818-102004.parquet\n"
     ]
    }
   ],
   "source": [
    "def ts():\n",
    "    return dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "csv_path=RAW_DIR/f\"prices_{ts()}.csv\"\n",
    "df.to_csv(csv_path,index=True)\n",
    "parq_path = PROC_DIR / f\"prices_{ts()}.parquet\"\n",
    "try:\n",
    "    df.to_parquet(parq_path, engine=\"fastparquet\")\n",
    "  # uses installed engine if available\n",
    "    print(\"Saved Parquet →\", parq_path)\n",
    "except Exception as e:\n",
    "    print(\"Parquet save failed (engine missing?). Skipping Parquet demo.\")\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94e33a81-1a9e-40d8-830b-64be3d0b5a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pyarrow-21.0.0-cp310-cp310-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/26.2 MB 16.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.3/26.2 MB 18.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.4/26.2 MB 25.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.3/26.2 MB 28.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 26.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-21.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyarrow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a09b3863-fd47-44aa-8f31-2ca884e220a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 2.3.1\n",
      "pyarrow: 21.0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, pyarrow as pa\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"pyarrow:\", pa.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b98c22a2-89d9-4d57-a951-cf3030cd0c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\bobli\\miniconda3\\envs\\fe-course\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\bobli\\miniconda3\\envs\\fe-course\\lib\\site-packages (21.0.0)\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.11.0-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\bobli\\miniconda3\\envs\\fe-course\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bobli\\miniconda3\\envs\\fe-course\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bobli\\miniconda3\\envs\\fe-course\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bobli\\miniconda3\\envs\\fe-course\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.11.0-cp310-cp310-win_amd64.whl.metadata (681 bytes)\n",
      "Collecting fsspec (from fastparquet)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\bobli\\miniconda3\\envs\\fe-course\\lib\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bobli\\miniconda3\\envs\\fe-course\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading fastparquet-2024.11.0-cp310-cp310-win_amd64.whl (670 kB)\n",
      "   ---------------------------------------- 0.0/670.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 670.7/670.7 kB 8.7 MB/s eta 0:00:00\n",
      "Downloading cramjam-2.11.0-cp310-cp310-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 23.0 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: fsspec, cramjam, fastparquet\n",
      "\n",
      "   -------------------------- ------------- 2/3 [fastparquet]\n",
      "   ---------------------------------------- 3/3 [fastparquet]\n",
      "\n",
      "Successfully installed cramjam-2.11.0 fastparquet-2024.11.0 fsspec-2025.7.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade pandas pyarrow fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcf1ac10-c903-4466-83b4-82bbb26415cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv validation: {'shape_equal': False, 'cols_present': True, 'price_is_numeric': True, 'date_is_datetime': True}\n"
     ]
    }
   ],
   "source": [
    "def validate_loaded(original,reloaded,cols=('date','ticker','price')):\n",
    "    checks={'shape_equal':original.shape==reloaded.shape,\n",
    "            'cols_present': all(c in reloaded.columns for c in cols)}\n",
    "    if 'price' in reloaded.columns:\n",
    "        checks['price_is_numeric'] = pd.api.types.is_numeric_dtype(reloaded['price'])\n",
    "    if 'date' in reloaded.columns:\n",
    "        checks['date_is_datetime'] = pd.api.types.is_datetime64_any_dtype(reloaded['date'])\n",
    "    return checks\n",
    "df_csv=pd.read_csv(csv_path,parse_dates=['date'])\n",
    "print('csv validation:',validate_loaded(df,df_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d35fb6e5-b905-4ec1-afea-dd8b7f6c87b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet validation: {'shape_equal': True, 'cols_present': True, 'price_is_numeric': True, 'date_is_datetime': True}\n"
     ]
    }
   ],
   "source": [
    "if parq_path.exists():\n",
    "    try:\n",
    "        df_parq = pd.read_parquet(parq_path,engine=\"fastparquet\")\n",
    "        print('Parquet validation:', validate_loaded(df, df_parq))\n",
    "    except Exception as e:\n",
    "        print('Parquet read failed:', e)\n",
    "else:\n",
    "    print('Parquet file not present (skipped earlier).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2bb2d4d8-196a-46cc-81d2-efda4f58861c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded CSV via util, shape: (10, 3)\n",
      "Reloaded Parquet via util, shape: (10, 3)\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "\n",
    "def ensure_dir(path:pathlib.Path):\n",
    "    path.parent.mkdir(parents=True,exist_ok=True)\n",
    "def detect_format(path:Union[str,pathlib.Path]):\n",
    "    suf=str(path).lower()\n",
    "    if suf.endswith('.csv'): return 'csv'\n",
    "    if suf.endswith('.parquet') or suf.endswith('.pq') or suf.endswith('.parq'): return 'parquet'\n",
    "    raise ValueError('Unsupported format for: ' + str(path))\n",
    "def write_df(df,path: Union[str, pathlib.Path]):\n",
    "    path=pathlib.Path(path)\n",
    "    ensure_dir(path)\n",
    "    fmt=detect_format(path)\n",
    "    if fmt=='csv':\n",
    "        df.to_csv(path,index=False)\n",
    "    elif fmt=='parquet':\n",
    "        try:\n",
    "            df.to_parquet(path,engine=\"fastparquet\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n",
    "    return path    \n",
    "def read_df(path: Union[str, pathlib.Path]):\n",
    "    path = pathlib.Path(path)\n",
    "    fmt = detect_format(path)\n",
    "    if fmt == 'csv':\n",
    "        return pd.read_csv(path, parse_dates=['date']) if 'date' in pd.read_csv(path, nrows=0).columns else pd.read_csv(path)\n",
    "    elif fmt == 'parquet':\n",
    "        try:\n",
    "            return pd.read_parquet(path,engine=\"fastparquet\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n",
    "csv2 = RAW_DIR / f\"prices_util_{ts()}.csv\"\n",
    "pq2  = PROC_DIR / f\"prices_util_{ts()}.parquet\"\n",
    "write_df(df, csv2)\n",
    "df2 = read_df(csv2)\n",
    "print('Reloaded CSV via util, shape:', df2.shape)\n",
    "\n",
    "try:\n",
    "    write_df(df, pq2)\n",
    "    df3 = read_df(pq2)\n",
    "    print('Reloaded Parquet via util, shape:', df3.shape)\n",
    "except RuntimeError as e:\n",
    "    print('Parquet util demo skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e94e06-08b5-4e2c-bc85-94a6eff4134a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fe-course)",
   "language": "python",
   "name": "fe-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
